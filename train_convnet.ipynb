{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from convnet import ConvNet\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "from CustomDataset import CustomTensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "from caxton_model.network_module import ParametersClassifier\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from lightning_model import LightningModel\n",
    "\n",
    "from utils import get_images_and_targets\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "ROOT_DATA_PATH = '/s/babbage/e/nobackup/nkrishna/m3x/others/data/'\n",
    "SAVING_OUTPUTS = './'\n",
    "train_set = ROOT_DATA_PATH + 'train.csv'\n",
    "test_set = ROOT_DATA_PATH + 'test.csv'\n",
    "images = ROOT_DATA_PATH + 'images/'\n",
    "MODEL_NAME = 'microsoft/resnet-50'\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "LEARNING_RATE = 1e-03\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "n_hiddens_per_conv_layer = [10, 10, 10]\n",
    "n_hiddens_per_fc_layer = [10, 10, 10]\n",
    "patch_size_per_conv_layer = [50, 10, 5]\n",
    "stride_per_conv_layer = [7, 3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(train_set)\n",
    "\n",
    "image_processor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61791/61791 [22:01<00:00, 46.75it/s]\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/s/babbage/e/nobackup/nkrishna/m3x/conda/envs/3dprint/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: lightning_logs/microsoft/resnet-50_convnet_lr_0.001_greater_than_cutoff_15\n",
      "/s/babbage/e/nobackup/nkrishna/m3x/conda/envs/3dprint/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /s/chopin/a/grad/sam97/3dprinting-error-detection/output/model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | conv_layers | ModuleList       | 87.5 K\n",
      "1 | fc_layers   | ModuleList       | 652   \n",
      "2 | criterion   | CrossEntropyLoss | 0     \n",
      "3 | softmax     | Softmax          | 0     \n",
      "-------------------------------------------------\n",
      "88.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "88.2 K    Total params\n",
      "0.176     Total estimated model params size (MB)\n",
      "2023-04-03 15:48:57.959807: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01640772819519043,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46c041e48214c43803fecf50a2de4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/babbage/e/nobackup/nkrishna/m3x/conda/envs/3dprint/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "training for images greater than cutoff\n",
    "'''\n",
    "trainX, trainY = get_images_and_targets(train_labels, images, image_processor, lesser=False)\n",
    "\n",
    "dataset_train = CustomTensorDataset(trainX, trainY)\n",
    "trainloader = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "\n",
    "model_greater = ConvNet(224*224, n_hiddens_per_conv_layer, n_hiddens_per_fc_layer, 2, patch_size_per_conv_layer, stride_per_conv_layer, learning_rate=LEARNING_RATE)\n",
    "\n",
    "print(\"model loaded\")\n",
    "\n",
    "if not os.path.exists('{}{}/'.format(SAVING_OUTPUTS, 'output/model')):\n",
    "    os.makedirs('{}{}/'.format(SAVING_OUTPUTS, 'output/model'))\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='train_f1',\n",
    "    dirpath='{}{}/'.format(SAVING_OUTPUTS, 'output/model'),\n",
    "    filename='{}-{}-{}-{}'.format(MODEL_NAME, '3dprint_convnet', LEARNING_RATE, BATCH_SIZE)+'-{epoch:02d}-{train_f1:.4f}_greater_than_cutoff',\n",
    "    save_top_k=5,\n",
    "    mode='max',\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor=\"train_f1\", min_delta=0.00, patience=10, verbose=False, mode=\"max\")\n",
    "\n",
    "\n",
    "logger = TensorBoardLogger('lightning_logs', name=f'{MODEL_NAME}_convnet_lr_{LEARNING_RATE}_greater_than_cutoff_{EPOCHS}')\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    precision=16,\n",
    "    accelerator='gpu', devices=[0],\n",
    "    num_sanity_val_steps=0,\n",
    "    # check_val_every_n_epoch=5,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    logger=logger,\n",
    "    # strategy='ddp'\n",
    ")\n",
    "\n",
    "print('Start Training...')\n",
    "trainer.fit(model_greater, trainloader)\n",
    "\n",
    "\n",
    "print(\"training done\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7831/7831 [02:57<00:00, 44.24it/s]\n",
      "79it [00:03, 20.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "CHECKPOINT_MODEL_PATH='./output/model/microsoft/resnet-50-3dprint_convnet-0.001-100-epoch=02-train_f1=0.9727_greater_than_cutoff.ckpt'\n",
    "\n",
    "test_labels = pd.read_csv(test_set)\n",
    "\n",
    "testX, imgpathsY = get_images_and_targets(test_labels, images, image_processor, test=True, lesser=False)\n",
    "dataset_test = CustomTensorDataset(testX, torch.ones(len(imgpathsY)).reshape(-1,1))\n",
    "testloader = DataLoader(dataset=dataset_test, batch_size=100, shuffle=False, num_workers=6)\n",
    "\n",
    "model_greater = ConvNet(224*224, n_hiddens_per_conv_layer, n_hiddens_per_fc_layer, 2, patch_size_per_conv_layer, stride_per_conv_layer, learning_rate=LEARNING_RATE).load_from_checkpoint(CHECKPOINT_MODEL_PATH,n_inputs =224*224, n_hiddens_per_conv_layer=n_hiddens_per_conv_layer, n_hiddens_per_fc_layer=n_hiddens_per_fc_layer, n_outputs=2, patch_size_per_conv_layer=patch_size_per_conv_layer, stride_per_conv_layer=stride_per_conv_layer, learning_rate=LEARNING_RATE)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model_greater = model_greater.cuda(device).eval()\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "gt_max, pred_max, probs_all = [], [], []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for idx, data in tqdm(enumerate(testloader)):\n",
    "\n",
    "        img_seq, label = data\n",
    "        \n",
    "        img_seq = img_seq.cuda(device)\n",
    "        \n",
    "        logits = model_greater(img_seq)\n",
    "\n",
    "\n",
    "        probs = softmax(logits)\n",
    "        preds = torch.max(probs, 1, keepdim=True)[1].int().cpu()\n",
    "        \n",
    "        \n",
    "        pred_max.append( preds)\n",
    "\n",
    "\n",
    "test_predictions = torch.vstack(pred_max).cpu()\n",
    "\n",
    "\n",
    "result = np.hstack((imgpathsY.reshape(-1,1), test_predictions.numpy()))\n",
    "\n",
    "results_df = pd.DataFrame(result, columns=['img_path', 'has_under_extrusion'])\n",
    "saving_name=MODEL_NAME.replace('/','_')\n",
    "results_df.to_csv(SAVING_OUTPUTS+f'results_{saving_name}_convnet_greater_than_cutoff.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19269/19269 [08:33<00:00, 37.49it/s]\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/s/babbage/e/nobackup/nkrishna/m3x/conda/envs/3dprint/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: lightning_logs/microsoft/resnet-50_convnet_lr_0.001_lesser_than_cutoff_15\n",
      "/s/babbage/e/nobackup/nkrishna/m3x/conda/envs/3dprint/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /s/chopin/a/grad/sam97/3dprinting-error-detection/output/model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | conv_layers | ModuleList       | 87.5 K\n",
      "1 | fc_layers   | ModuleList       | 652   \n",
      "2 | criterion   | CrossEntropyLoss | 0     \n",
      "3 | softmax     | Softmax          | 0     \n",
      "-------------------------------------------------\n",
      "88.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "88.2 K    Total params\n",
      "0.176     Total estimated model params size (MB)\n",
      "2023-04-03 16:58:40.578417: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016477108001708984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6a8606763440c48d7f01c693f0fdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/babbage/e/nobackup/nkrishna/m3x/conda/envs/3dprint/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "training for images lesser than cutoff\n",
    "'''\n",
    "trainX, trainY = get_images_and_targets(train_labels, images, image_processor, lesser=True)\n",
    "\n",
    "dataset_train = CustomTensorDataset(trainX, trainY)\n",
    "trainloader = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "\n",
    "model_lesser = ConvNet(224*224, n_hiddens_per_conv_layer, n_hiddens_per_fc_layer, 2, patch_size_per_conv_layer, stride_per_conv_layer, learning_rate=LEARNING_RATE)\n",
    "\n",
    "print(\"model loaded\")\n",
    "\n",
    "if not os.path.exists('{}{}/'.format(SAVING_OUTPUTS, 'output/model')):\n",
    "    os.makedirs('{}{}/'.format(SAVING_OUTPUTS, 'output/model'))\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='train_f1',\n",
    "    dirpath='{}{}/'.format(SAVING_OUTPUTS, 'output/model'),\n",
    "    filename='{}-{}-{}-{}'.format(MODEL_NAME, '3dprint_convnet', LEARNING_RATE, BATCH_SIZE)+'-{epoch:02d}-{train_f1:.4f}_lesser_than_cutoff',\n",
    "    save_top_k=5,\n",
    "    mode='max',\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor=\"train_f1\", min_delta=0.00, patience=10, verbose=False, mode=\"max\")\n",
    "\n",
    "\n",
    "logger = TensorBoardLogger('lightning_logs', name=f'{MODEL_NAME}_convnet_lr_{LEARNING_RATE}_lesser_than_cutoff_{EPOCHS}')\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    precision=16,\n",
    "    accelerator='gpu', devices=[0],\n",
    "    num_sanity_val_steps=0,\n",
    "    # check_val_every_n_epoch=5,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    logger=logger,\n",
    "    # strategy='ddp'\n",
    ")\n",
    "\n",
    "print('Start Training...')\n",
    "trainer.fit(model_lesser, trainloader)\n",
    "\n",
    "\n",
    "print(\"training done\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "CHECKPOINT_MODEL_PATH='./output/model/microsoft/resnet-50-3dprint_convnet-0.001-100-epoch=00-train_f1=0.8893_lesser_than_cutoff.ckpt'\n",
    "\n",
    "test_labels = pd.read_csv(test_set)\n",
    "\n",
    "testX, imgpathsY = get_images_and_targets(test_labels, images, image_processor, test=True, lesser=True)\n",
    "dataset_test = CustomTensorDataset(testX, torch.ones(len(imgpathsY)).reshape(-1,1))\n",
    "testloader = DataLoader(dataset=dataset_test, batch_size=100, shuffle=False, num_workers=6)\n",
    "\n",
    "model_lesser = ConvNet(224*224, n_hiddens_per_conv_layer, n_hiddens_per_fc_layer, 2, patch_size_per_conv_layer, stride_per_conv_layer, learning_rate=LEARNING_RATE).load_from_checkpoint(CHECKPOINT_MODEL_PATH,n_inputs =224*224, n_hiddens_per_conv_layer=n_hiddens_per_conv_layer, n_hiddens_per_fc_layer=n_hiddens_per_fc_layer, n_outputs=2, patch_size_per_conv_layer=patch_size_per_conv_layer, stride_per_conv_layer=stride_per_conv_layer, learning_rate=LEARNING_RATE)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model_lesser = model_lesser.cuda(device).eval()\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "gt_max, pred_max, probs_all = [], [], []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for idx, data in tqdm(enumerate(testloader)):\n",
    "\n",
    "        img_seq, label = data\n",
    "        \n",
    "        img_seq = img_seq.cuda(device)\n",
    "        \n",
    "        logits = model_lesser(img_seq)\n",
    "\n",
    "\n",
    "        probs = softmax(logits)\n",
    "        preds = torch.max(probs, 1, keepdim=True)[1].int().cpu()\n",
    "        \n",
    "        \n",
    "        pred_max.append( preds)\n",
    "\n",
    "\n",
    "test_predictions = torch.vstack(pred_max).cpu()\n",
    "\n",
    "\n",
    "result = np.hstack((imgpathsY.reshape(-1,1), test_predictions.numpy()))\n",
    "\n",
    "results_df = pd.DataFrame(result, columns=['img_path', 'has_under_extrusion'])\n",
    "saving_name=MODEL_NAME.replace('/','_')\n",
    "results_df.to_csv(SAVING_OUTPUTS+f'results_{saving_name}_convnet_lesser_than_cutoff.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
